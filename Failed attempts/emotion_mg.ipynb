{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0d012d5e-f0c7-4007-b774-c81c6687f087"
    }
   },
   "source": [
    "# Emotion Classification Using Transform Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d5a43d92-aa21-44d4-a3e2-fb918cee5508"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "%config IPCompleter.merge_completions = True\n",
    "%config IPCompleter.limit_to__all__ = False\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "23afba44-2d4a-41b2-b9cc-b55f0570b7df"
    }
   },
   "outputs": [],
   "source": [
    "drp = lasagne.layers.DropoutLayer\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "bnorm = lasagne.layers.batch_norm\n",
    "reg = lasagne.regularization.regularize_layer_params\n",
    "l2_loss = lasagne.regularization.l2\n",
    "CHANNELS_NUM = 1\n",
    "IMAGE_WIDTH = 48\n",
    "IMAGE_HIGHT = 48\n",
    "CLASSES_NUM = 7\n",
    "EPOCHS_NUM = 500\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001     #if from epoch 0, start with learning rate = 0.001\n",
    "DATASET_SIZE = 35887\n",
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Suprise', 4: 'Sad', 5: 'Happy', 6: 'Neutral'}\n",
    "FILE_NAME = \"fer2013/fer2013.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "87c516a8-c01f-43dd-aaa0-9eac1e0d0f49"
    }
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "043220d4-77ed-432b-a447-07eda267226e"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    X_data = np.zeros((DATASET_SIZE, IMAGE_HIGHT*IMAGE_WIDTH))\n",
    "    Y_data = np.zeros((DATASET_SIZE,))\n",
    " \n",
    "    i = 0\n",
    "    with open(FILE_NAME, 'rb') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            X_data[i, :] = np.fromstring(row['pixels'], dtype=int, sep=' ')\n",
    "            Y_data[i] = row['emotion']\n",
    "            i = i + 1\n",
    "            \n",
    "    X_data = X_data.reshape((-1, CHANNELS_NUM, IMAGE_HIGHT, IMAGE_WIDTH))\n",
    "    #print X_data.shape\n",
    "    #print Y_data.shape\n",
    "    \n",
    "    mask = np.random.choice(DATASET_SIZE, int((4.0/5)*DATASET_SIZE),False)     #Random numbers must be unique.\n",
    "   \n",
    "    X_train = X_data[mask, :, :, :] \n",
    "    Y_train = Y_data[mask]\n",
    "    X_val_tst = X_data[~mask, :, :, :] \n",
    "    Y_val_tst = Y_data[~mask]\n",
    "    val_mask = np.random.choice(X_val_tst.shape[0], int((1.0/10)*DATASET_SIZE),False)\n",
    "    X_valid = X_val_tst[val_mask, :, :, :]\n",
    "    X_test = X_val_tst[~val_mask, :, :, :]\n",
    "    Y_valid = Y_val_tst[val_mask]\n",
    "    Y_test = Y_val_tst[~val_mask]\n",
    "    \n",
    "    #print X_train.shape, X_valid.shape, X_test.shape\n",
    "    #print Y_train.shape, Y_valid.shape, Y_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train / 255.0),\n",
    "        y_train=Y_train.astype('int32'),\n",
    "        X_valid=lasagne.utils.floatX(X_valid / 255.0),\n",
    "        y_valid=Y_valid.astype('int32'),\n",
    "        X_test=lasagne.utils.floatX(X_test / 255.0),\n",
    "        y_test=Y_test.astype('int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=CLASSES_NUM,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4b372acc-6a81-4961-bbaf-7653779ebee3"
    }
   },
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "\n",
    "idx = 0\n",
    "canvas = np.zeros((IMAGE_HIGHT*10, 10*IMAGE_WIDTH))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        canvas[i*IMAGE_HIGHT:(i+1)*IMAGE_HIGHT, j*IMAGE_WIDTH:(j+1)*IMAGE_WIDTH] = data['X_train'][idx].reshape((IMAGE_HIGHT, IMAGE_WIDTH))\n",
    "        idx += 1\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.title('faces')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c6c851a9-57cf-4c9c-89db-d7cce5e461ff"
    }
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5dc199c9-ebef-46a8-8e02-9e655c686b83"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(input_width, input_height, output_dim,\n",
    "                batch_size=BATCH_SIZE):\n",
    "    ini = lasagne.init.HeNormal()\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "    \n",
    "    # Classification network\n",
    "    class_l1 = bnorm(conv(\n",
    "        l_in,\n",
    "        num_filters=16,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        stride = 1,\n",
    "        pad = 1\n",
    "    ))\n",
    "    l_drp1 = drp(class_l1, p=0.4)\n",
    "    class_l3 = bnorm(conv(\n",
    "        l_drp1,\n",
    "        num_filters=16,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        stride = 1,\n",
    "        pad = 1\n",
    "    ))\n",
    "    l_drp2 = drp(class_l3, p=0.4)\n",
    "    class_l4 = bnorm(conv(\n",
    "        l_drp2,\n",
    "        num_filters=8,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        stride = 1,\n",
    "        pad = 1\n",
    "    ))\n",
    "    l_drp3 = drp(class_l4, p=0.4)\n",
    "    class_l5 = bnorm(lasagne.layers.DenseLayer(\n",
    "        l_drp3,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    ))\n",
    "    l_drp3 = drp(class_l5, p=0.4)\n",
    "    l_out = bnorm(lasagne.layers.DenseLayer(\n",
    "        l_drp3,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    ))\n",
    "\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "dd8b807c-1f60-4ea7-b244-2485870215ee"
    }
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "model = build_model(IMAGE_HIGHT, IMAGE_WIDTH, CLASSES_NUM)\n",
    "model_params = lasagne.layers.get_all_params(model, trainable=True)\n",
    "\n",
    "# training output\n",
    "output_train = lasagne.layers.get_output(model, X, deterministic=False)\n",
    "\n",
    "# evaluation output. Also includes output of transform for plotting\n",
    "output_eval = lasagne.layers.get_output([model], X, deterministic=True)\n",
    "\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(output_train, y))\n",
    "l2_penalty = reg(model, l2_loss) * 1e-4\n",
    "reg_cost = cost + l2_penalty\n",
    "updates = lasagne.updates.adam(reg_cost, model_params, learning_rate=sh_lr)\n",
    "\n",
    "train = theano.function([X, y], [reg_cost, output_train], updates=updates)\n",
    "eval = theano.function([X], output_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4e2712de-4380-4088-b7d7-63696f27397b"
    }
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a1134dad-7304-45a5-b78b-88072ac08542"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        if i % 10 == 0:\n",
    "            print i,\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "        cost_batch, output_train = train(X_batch, y_batch)\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch == preds)\n",
    "    print \"\"\n",
    "    return np.mean(costs), correct / float(num_samples)\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    output_eval = eval(X)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ecb64a82-6fec-4631-9a25-c3f891c8a281"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "try:\n",
    "    for n in range(EPOCHS_NUM):\n",
    "        train_cost, train_acc = train_epoch(data['X_train'], data['y_train'])\n",
    "        valid_acc = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "        test_acc = eval_epoch(data['X_test'], data['y_test'])\n",
    "        valid_accs += [valid_acc]\n",
    "        test_accs += [test_acc]\n",
    "        train_accs += [train_acc]\n",
    "\n",
    "        if (n+1) % 20 == 0:\n",
    "            new_lr = sh_lr.get_value() * 0.7\n",
    "            print \"New LR:\", new_lr\n",
    "            sh_lr.set_value(lasagne.utils.floatX(new_lr))\n",
    "            #store\n",
    "            all_params = lasagne.layers.get_all_params(model)\n",
    "            all_param_values = [p.get_value() for p in all_params]\n",
    "            \n",
    "        if (n+1) % 10 == 0:\n",
    "            output = open('params_epoch{0}.oo'.format(n+1), 'wb')\n",
    "            pickle.dump(all_param_values, output)\n",
    "            output.close()\n",
    "            \n",
    "            \n",
    "        print \"Epoch {0}: Train cost {1}, Train acc {2}, val acc {3}, test acc {4}\".format(\n",
    "                n, train_cost, train_acc, valid_acc, test_acc)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e8653c88-392a-4c6d-8be3-d75d4c244a1a"
    }
   },
   "source": [
    "# Saving The Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b529808a-ac61-48f0-951d-990f74283f2b"
    }
   },
   "outputs": [],
   "source": [
    "#store\n",
    "all_params = lasagne.layers.get_all_params(model)\n",
    "all_param_values = [p.get_value() for p in all_params]\n",
    "\n",
    "output = open('final_params.oo', 'wb')\n",
    "pickle.dump(all_param_values, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dece5b21-4ddc-4d22-a499-f99422cbc549"
    }
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4d5bd4d1-00d7-4819-bc80-eff960f3e05a"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Error', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "48f23c16-1747-40b8-81d5-2ae42ed6b434"
    }
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b5e69c4c-375b-4fa9-bf54-c41af097f6ee"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "for i in range(9):\n",
    "    plt.subplot(331+i)\n",
    "    im = np.array(scipy.misc.imresize(plt.imread('test_images/{}.jpg'.format(i+1)),(IMAGE_HIGHT, IMAGE_WIDTH)))\n",
    "    im1 = rgb2gray(im).reshape((1,1,IMAGE_HIGHT,IMAGE_WIDTH))\n",
    "    plt.imshow(im, cmap='gray', interpolation='none')\n",
    "    output_eval = eval(im1)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    plt.title(emotions[preds[0][0]], fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a92a30a9-55ea-4e23-99c2-0d32f04d040b"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "for i in range(8):\n",
    "    plt.subplot(331+i)\n",
    "    im = np.array(scipy.misc.imresize(plt.imread('test_images/1{}.jpg'.format(i+1)),(IMAGE_HIGHT, IMAGE_WIDTH)))\n",
    "    im1 = rgb2gray(im).reshape((1,1,IMAGE_HIGHT,IMAGE_WIDTH))\n",
    "    plt.imshow(im, cmap='gray', interpolation='none')\n",
    "    output_eval = eval(im1)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    plt.title(emotions[preds[0][0]], fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e0f6ad8a-99f3-42ac-9f3b-44f3d97adb60"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "for i in range(5):\n",
    "    plt.subplot(331+i)\n",
    "    im = np.array(scipy.misc.imresize(plt.imread('test_images/2{}.jpg'.format(i+1)),(IMAGE_HIGHT, IMAGE_WIDTH)))\n",
    "    im1 = rgb2gray(im).reshape((1,1,IMAGE_HIGHT,IMAGE_WIDTH))\n",
    "    plt.imshow(im, cmap='gray', interpolation='none')\n",
    "    output_eval = eval(im1)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    plt.title(emotions[preds[0][0]], fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6c7c7742-b48c-4516-a990-372100894c61"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

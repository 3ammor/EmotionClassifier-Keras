{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "%config IPCompleter.merge_completions = True\n",
    "%config IPCompleter.limit_to__all__ = False\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHANNELS_NUM = 1\n",
    "IMAGE_WIDTH = 48\n",
    "IMAGE_HIGHT = 48\n",
    "CLASSES_NUM = 7\n",
    "EPOCHS_NUM = 80\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001     #if from epoch 0, start with learning rate = 0.001\n",
    "DATASET_SIZE = 35887\n",
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Suprise', 4: 'Sad', 5: 'Happy', 6: 'Neutral'}\n",
    "FILE_NAME = \"fer2013/fer2013.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    X_data = np.zeros((DATASET_SIZE, IMAGE_HIGHT*IMAGE_WIDTH))\n",
    "    Y_data = np.zeros((DATASET_SIZE,))\n",
    " \n",
    "    i = 0\n",
    "    with open(FILE_NAME, 'rb') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            X_data[i, :] = np.fromstring(row['pixels'], dtype=int, sep=' ')\n",
    "            Y_data[i] = row['emotion']\n",
    "            i = i + 1\n",
    "            \n",
    "    X_data = X_data.reshape((-1, CHANNELS_NUM, IMAGE_HIGHT, IMAGE_WIDTH))\n",
    "    #print X_data.shape\n",
    "    #print Y_data.shape\n",
    "    \n",
    "    #############################################\n",
    "    mask = np.random.choice(DATASET_SIZE, int((4.0/5)*DATASET_SIZE),replace = False)     #Random numbers must be unique.\n",
    "   \n",
    "    #Save the training data mask\n",
    "    output = open('TrainingDataMask.oo', 'wb')\n",
    "    pickle.dump(mask, output)\n",
    "    output.close()\n",
    "    \n",
    "    #Load the training data mask\n",
    "    #output = open('TrainingDataMask.oo', 'rb')\n",
    "    #mask = pickle.load(output)\n",
    "    #############################################\n",
    "    \n",
    "    X_train = X_data[mask, :, :, :] \n",
    "    Y_train = Y_data[mask]\n",
    "    X_val_tst = X_data[~mask, :, :, :] \n",
    "    Y_val_tst = Y_data[~mask]\n",
    "    \n",
    "    \n",
    "    val_mask = np.random.choice(X_val_tst.shape[0], int((1.0/10)*DATASET_SIZE),replace = False)\n",
    "    \n",
    "    #############################################\n",
    "    #Save the validation data mask\n",
    "    output = open('ValDataMask.oo', 'wb')\n",
    "    pickle.dump(val_mask, output)\n",
    "    output.close()\n",
    "    \n",
    "    #Load the validation data mask\n",
    "    #output = open('ValDataMask.oo', 'rb')\n",
    "    #val_mask = pickle.load(output)\n",
    "    #############################################\n",
    "    \n",
    "    X_valid = X_val_tst[val_mask, :, :, :]\n",
    "    X_test = X_val_tst[~val_mask, :, :, :]\n",
    "    Y_valid = Y_val_tst[val_mask]\n",
    "    Y_test = Y_val_tst[~val_mask]\n",
    "    \n",
    "    #print X_train.shape, X_valid.shape, X_test.shape\n",
    "    #print Y_train.shape, Y_valid.shape, Y_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=(X_train/255.0).astype('float32'),\n",
    "        y_train=np_utils.to_categorical(Y_train.astype('uint8')),\n",
    "        X_valid=(X_valid / 255.0).astype('float32'),\n",
    "        y_valid=np_utils.to_categorical(Y_valid.astype('uint8')),\n",
    "        X_test=(X_test / 255.0).astype('float32'),\n",
    "        y_test=np_utils.to_categorical(Y_test.astype('uint8')),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=CLASSES_NUM,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BuildModel():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, 3, 3, init = 'he_normal', input_shape=(CHANNELS_NUM, IMAGE_WIDTH, IMAGE_HIGHT), border_mode='same', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Convolution2D(16, 3, 3, init = 'he_normal', input_shape=(CHANNELS_NUM, IMAGE_WIDTH, IMAGE_HIGHT), border_mode='same', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Convolution2D(32, 3, 3, init = 'he_normal', input_shape=(CHANNELS_NUM, IMAGE_WIDTH, IMAGE_HIGHT), border_mode='same', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.4))  \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, init = 'he_normal', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(128, init = 'he_normal', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(CLASSES_NUM, init = 'he_normal', W_regularizer = l2(1e-4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))  \n",
    "    # Compile model\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.99)\n",
    "    \n",
    "    #load the model from a saved file\n",
    "    #model.load_weights(\"weights.best.hdf5\")\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BuildModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #save the currently best weights.\n",
    "    filepath=\"weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "        \n",
    "    history = model.fit(data['X_train'], data['y_train'], callbacks=callbacks_list, validation_data=(data['X_valid'], data['y_valid']),shuffle=True, nb_epoch=EPOCHS_NUM, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(data['X_test'], data['y_test'], verbose=1)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "    #Save the model.\n",
    "    model.save_weights(\"model1epoch80.h5\")\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the model.\n",
    "model.load_weights(\"model1epoch80.h5\")\n",
    "scores = model.evaluate(data['X_test'], data['y_test'], verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "for i in range(9):\n",
    "    plt.subplot(331+i)\n",
    "    im = np.array(scipy.misc.imresize(plt.imread('test_images/1{}.jpg'.format(i+1)),(IMAGE_HIGHT, IMAGE_WIDTH)))\n",
    "    im1 = rgb2gray(im).reshape((1,1,IMAGE_HIGHT,IMAGE_WIDTH))\n",
    "    plt.imshow(im, cmap='gray', interpolation='none')\n",
    "    output_eval = model.predict(im1, batch_size=BATCH_SIZE, verbose=1)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    plt.title(emotions[preds[0]], fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
